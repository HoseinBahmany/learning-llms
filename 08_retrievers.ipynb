{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1tasqOH8ELK3SJxVCV7x_6eI5mGXlhdgc",
      "authorship_tag": "ABX9TyPyYV9UurxyLIW6wwPgQsmG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HoseinBahmany/learning-llms/blob/main/08_retrievers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBLCNaEvsnIU"
      },
      "outputs": [],
      "source": [
        "!pip install langchain openai chromadb tiktoken numpy faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "os.environ[\"SERPAPI_API_KEY\"] = \"1516792b8aa8d598271fd69823f3590da610d429c776fff1deca86f4415bc818\""
      ],
      "metadata": {
        "id": "8Di7wLy2spcN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A retriever is an interface that returns documents given an unstructured query. It is more general than a vector store. A retriever does not need to be able to store documents, only to return (or retrieve) it. Vector stores can be used as the backbone of a retriever, but there are other types of retrievers as well.\n",
        "\n",
        "The public API of the `BaseRetriever` class in LangChain is as follows:\n",
        "\n",
        "```python\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import Any, List\n",
        "from langchain.schema import Document\n",
        "from langchain.callbacks.manager import Callbacks\n",
        "\n",
        "class BaseRetriever(ABC):\n",
        "    ...\n",
        "    def get_relevant_documents(\n",
        "        self, query: str, *, callbacks: Callbacks = None, **kwargs: Any\n",
        "    ) -> List[Document]:\n",
        "        \"\"\"Retrieve documents relevant to a query.\n",
        "        Args:\n",
        "            query: string to find relevant documents for\n",
        "            callbacks: Callback manager or list of callbacks\n",
        "        Returns:\n",
        "            List of relevant documents\n",
        "        \"\"\"\n",
        "        ...\n",
        "\n",
        "    async def aget_relevant_documents(\n",
        "        self, query: str, *, callbacks: Callbacks = None, **kwargs: Any\n",
        "    ) -> List[Document]:\n",
        "        \"\"\"Asynchronously get documents relevant to a query.\n",
        "        Args:\n",
        "            query: string to find relevant documents for\n",
        "            callbacks: Callback manager or list of callbacks\n",
        "        Returns:\n",
        "            List of relevant documents\n",
        "        \"\"\"\n",
        "        ...\n",
        "```\n",
        "\n",
        "It's that simple! You can call `get_relevant_documents` or the async `get_relevant_documents` methods to retrieve documents relevant to a query, where \"relevance\" is defined by the specific retriever object you are calling.\n",
        "\n",
        "The main type of Retriever that we focus on is a Vectorstore retriever. We will focus on that for the rest of this guide.\n",
        "\n",
        "This example showcases question answering over documents. We have chosen this as the example for getting started because it nicely combines a lot of different elements (Text splitters, embeddings, vectorstores) and then also shows how to use them in a chain.\n",
        "\n",
        "Question answering over documents consists of four steps:\n",
        "\n",
        "1. Create an index\n",
        "2. Create a Retriever from that index\n",
        "3. Create a question answering chain\n",
        "4. Ask questions!\n",
        "\n",
        "Each of the steps has multiple sub steps and potential configurations."
      ],
      "metadata": {
        "id": "M-cb7-wYsyAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "loader = TextLoader(\"/content/drive/MyDrive/Colab Notebooks/Data/state_of_the_union.txt\")\n",
        "\n",
        "# Creating the index\n",
        "index = VectorstoreIndexCreator(vectorstore_cls=FAISS).from_loaders([loader])"
      ],
      "metadata": {
        "id": "icZCQ7XntlX7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the index is created, we can use it to ask questions of the data!"
      ],
      "metadata": {
        "id": "WmlD1MUxu5kO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "index.query(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "nezCi1Ddu6Ce",
        "outputId": "2ff695f8-58a4-410d-f489-c87584835526"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" The president said that Ketanji Brown Jackson is one of the nation's top legal minds, a former top litigator in private practice, a former federal public defender, and from a family of public school educators and police officers. He also said that she is a consensus builder and has received a broad range of support from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "index.query_with_sources(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mP6WunovC--",
        "outputId": "16774a3d-3d30-4115-a68e-aef28af50a9c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'What did the president say about Ketanji Brown Jackson',\n",
              " 'answer': \" The president said that he nominated Circuit Court of Appeals Judge Ketanji Brown Jackson, one of the nation's top legal minds, to continue Justice Breyer's legacy of excellence, and that she has received a broad range of support from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.\\n\",\n",
              " 'sources': '/content/drive/MyDrive/Colab Notebooks/Data/state_of_the_union.txt'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Diving in VectorstoreIndexCreator\n",
        "\n",
        "A lot of the magic is being hid in this VectorstoreIndexCreator. What is this doing?\n",
        "\n",
        "There are three main steps going on after the documents are loaded:\n",
        "\n",
        "1. Splitting documents into chunks\n",
        "1. Creating embeddings for each document\n",
        "1. Storing documents and embeddings in a vectorstore"
      ],
      "metadata": {
        "id": "Kk1gQx2_vW2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "\n",
        "loader = TextLoader(\"/content/drive/MyDrive/Colab Notebooks/Data/state_of_the_union.txt\")\n",
        "raw_documents = loader.load()\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "documents = text_splitter.split_documents(raw_documents)\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "db = FAISS.from_documents(documents, embeddings)\n",
        "\n",
        "retriever = db.as_retriever()\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=retriever)\n",
        "\n",
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "cEZ4RmKyx2yl",
        "outputId": "fc1843ec-7a9a-437a-c66b-1b8fe4841321"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" The president said that Ketanji Brown Jackson is a Circuit Court of Appeals Judge, one of the nation's top legal minds, a former top litigator in private practice, a former federal public defender, from a family of public school educators and police officers, and a consensus builder with broad support from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VectorstoreIndexCreator is just a wrapper around all this logic. It is configurable in the text splitter it uses, the embeddings it uses, and the vectorstore it uses. For example, you can configure it as below:\n",
        "\n",
        "```python\n",
        "index_creator = VectorstoreIndexCreator(\n",
        "    vectorstore_cls=Chroma,\n",
        "    embedding=OpenAIEmbeddings(),\n",
        "    text_splitter=CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "K_MExzOQy6Lj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MultiQueryRetriever\n",
        "\n",
        "Distance-based vector database retrieval embeds (represents) queries in high-dimensional space and finds similar embedded documents based on \"distance\". But, retrieval may produce difference results with subtle changes in query wording or if the embeddings do not capture the semantics of the data well. Prompt engineering / tuning is sometimes done to manually address these problems, but can be tedious.\n",
        "\n",
        "The `MultiQueryRetriever` automates the process of prompt tuning by using an LLM to generate multiple queries from different perspectives for a given user input query. For each query, it retrieves a set of relevant documents and takes the unique union across all queries to get a larger set of potentially relevant documents. By generating multiple perspectives on the same question, the `MultiQueryRetriever` might be able to overcome some of the limitations of the distance-based retrieval and get a richer set of results."
      ],
      "metadata": {
        "id": "SBA7XtcZzeqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "import logging\n",
        "\n",
        "logging.basicConfig()\n",
        "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)\n",
        "\n",
        "# Load blog post\n",
        "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
        "data = loader.load()\n",
        "\n",
        "# Split document\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
        "document_splits = text_splitter.split_documents(data)\n",
        "\n",
        "# Setup VectorDB\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectordb = FAISS.from_documents(document_splits, embeddings)\n",
        "retriever = vectordb.as_retriever()\n",
        "\n",
        "# Setup llm\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "# Setup multi query retriever\n",
        "multi_query_retriver = MultiQueryRetriever.from_llm(retriever=retriever, llm=llm)\n",
        "\n",
        "question = \"What are the approaches to Task Decomposition?\"\n",
        "unique_docs = multi_query_retriver.get_relevant_documents(query=question)\n",
        "print(unique_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUqUkTPyzlMJ",
        "outputId": "e4f8a289-c0f3-4623-bdcd-3ef500596bde"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:langchain.retrievers.multi_query:Generated queries: ['1. How can Task Decomposition be approached?', '2. What are the different methods for Task Decomposition?', '3. What are the various approaches to decomposing tasks?']\n",
            "WARNING:langchain.embeddings.openai:Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-lvFdqyCbaZKezaPEG8TBnQnW on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.embeddings.openai:Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-lvFdqyCbaZKezaPEG8TBnQnW on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.embeddings.openai:Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-lvFdqyCbaZKezaPEG8TBnQnW on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.embeddings.openai:Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-lvFdqyCbaZKezaPEG8TBnQnW on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}), Document(page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}), Document(page_content='Challenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}), Document(page_content='Planning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}), Document(page_content='(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also supply a prompt along with an output parser to split the results into a list of queries."
      ],
      "metadata": {
        "id": "mCJEaPaf1GAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from langchain.chains import LLMChain\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "# Output parser will split the LLM result into a list of queries\n",
        "class LineList(BaseModel):\n",
        "    # \"lines\" is the key (attribute name) of the parsed output\n",
        "    lines: List[str] = Field(description=\"Lines of text\")\n",
        "\n",
        "class LineListOutputParser(PydanticOutputParser):\n",
        "    def __init__(self) -> None:\n",
        "      super().__init__(pydantic_object=LineList)\n",
        "\n",
        "    def parse(self, text: str) -> LineList:\n",
        "      lines = text.strip().split(\"\\n\")\n",
        "      return LineList(lines=lines)\n",
        "\n",
        "output_parser = LineListOutputParser()\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"\"\"You are an AI language model assistant. Your task is to generate five\n",
        "    different versions of the given user question to retrieve relevant documents from a vector\n",
        "    database. By generating multiple perspectives on the user question, your goal is to help\n",
        "    the user overcome some of the limitations of the distance-based similarity search.\n",
        "    Provide these alternative questions seperated by newlines.\n",
        "    Original question: {question}\"\"\"\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(temperature=0)\n",
        "chain = LLMChain(llm=llm, prompt=prompt, output_parser=output_parser)\n",
        "\n",
        "multi_query_retriver = MultiQueryRetriever(\n",
        "    retriever=retriever,\n",
        "    llm_chain=chain,\n",
        "    parser_key=\"lines\" # \"lines\" is the key (attribute name) of the parsed output\n",
        ")\n",
        "\n",
        "unique_docs = retriever.get_relevant_documents(\n",
        "    query=\"What does the course say about regression?\"\n",
        ")\n",
        "print(unique_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPve4xWB1I5E",
        "outputId": "b3d38852-37f2-4a32-9088-071abaa00333"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='They did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}), Document(page_content='\\\\dots \\\\geq r_1$ The process is supervised fine-tuning where the data is a sequence in the form of $\\\\tau_h = (x, z_i, y_i, z_j, y_j, \\\\dots, z_n, y_n)$, where $\\\\leq i \\\\leq j \\\\leq n$. The model is finetuned to only predict $y_n$ where conditioned on the sequence prefix, such that the model can self-reflect to produce better output based on the feedback sequence. The model can optionally receive multiple rounds of instructions with human annotators at test time.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}), Document(page_content='... (Repeated many times)', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}), Document(page_content='Fig. 5. After fine-tuning with CoH, the model can follow instructions to produce outputs with incremental improvement in a sequence. (Image source: Liu et al. 2023)', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'})]\n"
          ]
        }
      ]
    }
  ]
}